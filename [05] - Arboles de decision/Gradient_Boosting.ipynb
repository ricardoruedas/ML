{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ricardoruedas/ML/blob/main/%5B05%5D%20-%20Arboles%20de%20decision/Gradient_Boosting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc9eb426"
      },
      "source": [
        "# Arboles de decisi√≥n: Gradient Boosting - Ejercicio 2: Gradient_Boosting.ipynb\n",
        "\n",
        "Este notebook es un **I do**: todo resuelto y explicado paso a paso."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72867a89"
      },
      "source": [
        "## Objetivos\n",
        "\n",
        "- Creo un dataset alearotio con 1000 ejemplos de emails para detector de SPAM\n",
        "- Entrena un Gradient Boosting.\n",
        "- Eval√∫a el modelo con m√©tricas de clasificaci√≥n (accuracy, matriz de confusi√≥n y reporte).\n",
        "- Muestra la importancia de cada caracter√≠stica (qu√© variables usa m√°s el modelo para decidir)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHcmvQLHYcbB"
      },
      "source": [
        "## 1) Cargamos librerias clasificacion y regresion"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cargo librerias\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\n",
        "from sklearn.datasets import make_classification, make_regression\n",
        "from sklearn.metrics import accuracy_score, mean_squared_error\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# La filosofia del Gradient Boosting\n",
        "\n",
        "print(\"LA FILOSOF√çA DE GRADIENT BOOSTING:\")\n",
        "print(\"-\" * 40)\n",
        "print(\"üìö Random Forest: '¬øQu√© opinan 100 expertos?'\")\n",
        "print(\"üéØ Gradient Boosting: '¬øC√≥mo mejoro mi predicci√≥n paso a paso?'\")\n",
        "print(\"\\nüîÑ Proceso:\")\n",
        "print(\"   Modelo 1 ‚Üí Errores ‚Üí Modelo 2 ‚Üí Errores ‚Üí Modelo 3 ‚Üí ...\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9a-7sRkDWiH8",
        "outputId": "f38e1674-3f01-40e4-c560-501f234568f1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LA FILOSOF√çA DE GRADIENT BOOSTING:\n",
            "----------------------------------------\n",
            "üìö Random Forest: '¬øQu√© opinan 100 expertos?'\n",
            "üéØ Gradient Boosting: '¬øC√≥mo mejoro mi predicci√≥n paso a paso?'\n",
            "\n",
            "üîÑ Proceso:\n",
            "   Modelo 1 ‚Üí Errores ‚Üí Modelo 2 ‚Üí Errores ‚Üí Modelo 3 ‚Üí ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "624da4a8"
      },
      "source": [
        "## 2) Descripci√≥n del dataset (Ejemplo de clasificacion)\n",
        "\n",
        "El dataset de emails contiene 1000 muestras de emails potencialmente sospechosos, creados de manera random, dividido en 5 categorias diferentes.\n",
        "    'palabras_sospechosas',\n",
        "    'signos_exclamacion',\n",
        "    'enlaces_externos',\n",
        "    'mayusculas_porcentaje',\n",
        "    'longitud_email'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Crear datos simulados de emails\n",
        "np.random.seed(42)\n",
        "X_clf, y_clf = make_classification(\n",
        "    n_samples=1000,\n",
        "    n_features=5,\n",
        "    n_informative=3,\n",
        "    n_redundant=1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# Nombres m√°s intuitivos para las caracter√≠sticas\n",
        "feature_names = [\n",
        "    'palabras_sospechosas',\n",
        "    'signos_exclamacion',\n",
        "    'enlaces_externos',\n",
        "    'mayusculas_porcentaje',\n",
        "    'longitud_email'\n",
        "]\n",
        "\n",
        "df_emails = pd.DataFrame(X_clf, columns=feature_names)\n",
        "df_emails['es_spam'] = y_clf\n",
        "\n",
        "print(\"üìä Primeros 5 emails:\")\n",
        "print(df_emails.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rXZfSusCXcUp",
        "outputId": "eb7ae5f5-9386-4bfd-da64-b239914d1930"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìä Primeros 5 emails:\n",
            "   palabras_sospechosas  signos_exclamacion  enlaces_externos  \\\n",
            "0             -0.038769           -0.649239         -0.224746   \n",
            "1              1.005284           -1.373239          1.157346   \n",
            "2             -0.742455           -0.573257          1.688442   \n",
            "3             -1.587158            1.758582         -0.930664   \n",
            "4              0.195806           -0.058897         -0.549360   \n",
            "\n",
            "   mayusculas_porcentaje  longitud_email  es_spam  \n",
            "0              -1.346275        0.126879        0  \n",
            "1               0.126493        1.422799        0  \n",
            "2              -2.588237        0.762562        0  \n",
            "3               0.764614        2.415399        1  \n",
            "4               0.777375        1.147261        1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9Jv6BE7Yiw3"
      },
      "source": [
        "## 3) Dividimos train y test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir datos al 30%\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_clf, y_clf, test_size=0.3, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "E-7NyzlfXeuM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mppifkDYx5s"
      },
      "source": [
        "## 4) Cargamos el Gradient Boosting Classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ryz2Szlh_m4R",
        "outputId": "14c3008b-a45f-450e-9a3b-acb5e47b9d27"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ENTRENANDO GRADIENT BOOSTING:\n",
            "----------------------------------------\n",
            "‚öôÔ∏è  Configuraci√≥n:\n",
            "   üå≥ N√∫mero de √°rboles: 50\n",
            "   üìö Tasa de aprendizaje: 0.1\n",
            "   üìè Profundidad m√°xima: 3\n",
            "\n",
            "üîÑ Entrenando modelo...\n",
            "‚úÖ Precisi√≥n obtenida: 0.940 (94.0%)\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n ENTRENANDO GRADIENT BOOSTING:\")\n",
        "print(\"-\" * 40)\n",
        "\n",
        "# Crear el modelo\n",
        "gbm_clf = GradientBoostingClassifier(\n",
        "    n_estimators=50,        # 50 √°rboles secuenciales\n",
        "    learning_rate=0.1,      # Qu√© tanto aprende en cada paso\n",
        "    max_depth=3,           # √Årboles peque√±os (weak learners)\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"‚öôÔ∏è  Configuraci√≥n:\")\n",
        "print(f\"   üå≥ N√∫mero de √°rboles: {gbm_clf.n_estimators}\")\n",
        "print(f\"   üìö Tasa de aprendizaje: {gbm_clf.learning_rate}\")\n",
        "print(f\"   üìè Profundidad m√°xima: {gbm_clf.max_depth}\")\n",
        "\n",
        "# Entrenar\n",
        "print(\"\\nüîÑ Entrenando modelo...\")\n",
        "gbm_clf.fit(X_train, y_train)\n",
        "\n",
        "# Predicciones\n",
        "y_pred = gbm_clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"‚úÖ Precisi√≥n obtenida: {accuracy:.3f} ({accuracy*100:.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Como aprende el modelo, resultados"
      ],
      "metadata": {
        "id": "Y8IxQpEhbD7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n VIENDO C√ìMO APRENDE PASO A PASO:\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Calcular error por cada √°rbol a√±adido\n",
        "train_scores = gbm_clf.train_score_\n",
        "test_scores = []\n",
        "\n",
        "for i in range(1, gbm_clf.n_estimators + 1):\n",
        "    # Crear modelo con solo i √°rboles\n",
        "    temp_model = GradientBoostingClassifier(\n",
        "        n_estimators=i,\n",
        "        learning_rate=gbm_clf.learning_rate,\n",
        "        max_depth=gbm_clf.max_depth,\n",
        "        random_state=42\n",
        "    )\n",
        "    temp_model.fit(X_train, y_train)\n",
        "    pred = temp_model.predict(X_test)\n",
        "    test_scores.append(accuracy_score(y_test, pred))\n",
        "\n",
        "# Mostrar evoluci√≥n\n",
        "print(\"üìà Evoluci√≥n del modelo:\")\n",
        "for i in [1, 10, 20, 30, 40, 50]:\n",
        "    if i <= len(test_scores):\n",
        "        print(f\"   Despu√©s de {i:2d} √°rboles: {test_scores[i-1]:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IZOS78YqZKRx",
        "outputId": "60bd733b-f467-4110-e397-ebeff2513cd4"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " VIENDO C√ìMO APRENDE PASO A PASO:\n",
            "--------------------------------------------------\n",
            "üìà Evoluci√≥n del modelo:\n",
            "   Despu√©s de  1 √°rboles: 0.913\n",
            "   Despu√©s de 10 √°rboles: 0.950\n",
            "   Despu√©s de 20 √°rboles: 0.940\n",
            "   Despu√©s de 30 √°rboles: 0.940\n",
            "   Despu√©s de 40 √°rboles: 0.940\n",
            "   Despu√©s de 50 √°rboles: 0.940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T6CwqiC8bB-I"
      },
      "source": [
        "## 6) Descripci√≥n del dataset (Ejemplo de regresi√≥n)\n",
        "\n",
        "El dataset de emails contiene 500 muestras de precios de casas, dividido en 4 categorias diferentes.\n",
        "    'metros_cuadrados',\n",
        "    'num_habitaciones',\n",
        "    'antiguedad',\n",
        "    'distancia_centro'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n EJEMPLO DE REGRESI√ìN: PRECIOS DE CASAS\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Datos simulados de casas\n",
        "X_reg, y_reg = make_regression(\n",
        "    n_samples=500,\n",
        "    n_features=4,\n",
        "    noise=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "house_features = [\n",
        "    'metros_cuadrados',\n",
        "    'num_habitaciones',\n",
        "    'antiguedad',\n",
        "    'distancia_centro'\n",
        "]\n",
        "\n",
        "df_casas = pd.DataFrame(X_reg, columns=house_features)\n",
        "df_casas['precio'] = y_reg\n",
        "\n",
        "print(\"üè† Primeras 5 casas:\")\n",
        "print(df_casas.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j70HoN2tZUWG",
        "outputId": "c9757561-628b-4f55-dba2-43f9fea6d548"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " EJEMPLO DE REGRESI√ìN: PRECIOS DE CASAS\n",
            "--------------------------------------------------\n",
            "üè† Primeras 5 casas:\n",
            "   metros_cuadrados  num_habitaciones  antiguedad  distancia_centro     precio\n",
            "0         -0.923233         -1.406661   -0.611518         -1.351685 -81.342131\n",
            "1         -1.344451         -0.281785   -0.420187         -0.918652 -75.999739\n",
            "2         -2.067442         -0.032695    0.384065         -0.089120 -57.612023\n",
            "3          0.307407         -0.276813   -0.221254          0.815737   8.807619\n",
            "4          0.916328         -1.998201    0.078635          0.346488  25.887176\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGhUrr2ib2i5"
      },
      "source": [
        "## 7) Dividimos train y test"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Dividir datos\n",
        "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
        "    X_reg, y_reg, test_size=0.3, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "AsellJCCbqmA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 8) Cargamos el Gradient Boosting Regresion"
      ],
      "metadata": {
        "id": "PNLhjlUWb68a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Modelo de regresi√≥n\n",
        "gbm_reg = GradientBoostingRegressor(\n",
        "    n_estimators=100,\n",
        "    learning_rate=0.1,\n",
        "    max_depth=4,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(\"\\nüîÑ Entrenando modelo de regresi√≥n...\")\n",
        "gbm_reg.fit(X_train_reg, y_train_reg)\n",
        "\n",
        "# Predicciones\n",
        "y_pred_reg = gbm_reg.predict(X_test_reg)\n",
        "mse = mean_squared_error(y_test_reg, y_pred_reg)\n",
        "\n",
        "print(f\"‚úÖ Error cuadr√°tico medio: {mse:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1hfX3FEbsK9",
        "outputId": "7c6836ea-8d61-46ac-8268-7026a221fdf4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÑ Entrenando modelo de regresi√≥n...\n",
            "‚úÖ Error cuadr√°tico medio: 134.586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 9) Importancia de caracter√≠sticas"
      ],
      "metadata": {
        "id": "k5ZxXg4UucEo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# INTERPRETABILIDAD - ¬øQU√â CARACTER√çSTICAS SON IMPORTANTES?\n",
        "\n",
        "print(\"\\n ¬øQU√â CARACTER√çSTICAS SON M√ÅS IMPORTANTES?\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "# Para clasificaci√≥n (spam)\n",
        "importance_clf = gbm_clf.feature_importances_\n",
        "print(\"üìß Para detectar SPAM:\")\n",
        "for i, imp in enumerate(importance_clf):\n",
        "    print(f\"   {feature_names[i]:20s}: {imp:.3f}\")\n",
        "\n",
        "# Para regresi√≥n (casas)\n",
        "importance_reg = gbm_reg.feature_importances_\n",
        "print(\"\\nüè† Para predecir PRECIOS:\")\n",
        "for i, imp in enumerate(importance_reg):\n",
        "    print(f\"   {house_features[i]:20s}: {imp:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVu4chgeZihl",
        "outputId": "e84d4ef9-da28-4ec2-f456-19e17bd17117"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " ¬øQU√â CARACTER√çSTICAS SON M√ÅS IMPORTANTES?\n",
            "--------------------------------------------------\n",
            "üìß Para detectar SPAM:\n",
            "   palabras_sospechosas: 0.035\n",
            "   signos_exclamacion  : 0.136\n",
            "   enlaces_externos    : 0.000\n",
            "   mayusculas_porcentaje: 0.780\n",
            "   longitud_email      : 0.048\n",
            "\n",
            "üè† Para predecir PRECIOS:\n",
            "   metros_cuadrados    : 0.412\n",
            "   num_habitaciones    : 0.007\n",
            "   antiguedad          : 0.525\n",
            "   distancia_centro    : 0.057\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 10) Comparativa"
      ],
      "metadata": {
        "id": "wNS8zMh9coAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#COMPARACI√ìN CON RANDOM FOREST\n",
        "\n",
        "print(\"\\n GRADIENT BOOSTING vs RANDOM FOREST\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Entrenar Random Forest para comparar\n",
        "rf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "rf_pred = rf.predict(X_test)\n",
        "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
        "\n",
        "print(f\"üéØ Gradient Boosting: {accuracy:.3f}\")\n",
        "print(f\"üå≥ Random Forest:     {rf_accuracy:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPBLS9fBcM6h",
        "outputId": "c76824dd-f687-4004-c46f-75dfacbc4aed"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " GRADIENT BOOSTING vs RANDOM FOREST\n",
            "--------------------------------------------------\n",
            "üéØ Gradient Boosting: 0.940\n",
            "üå≥ Random Forest:     0.943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 11) Conclusion y Consejos Pr√°cticos\n",
        "\n",
        "üìù PAR√ÅMETROS CLAVE:\n",
        "   * n_estimators: M√°s √°rboles = mejor, pero cuidado con sobreajuste\n",
        "   * learning_rate: Entre 0.01-0.3. M√°s bajo = m√°s lento pero m√°s estable\n",
        "   * max_depth: 3-8 t√≠picamente. √Årboles simples funcionan mejor\n",
        "\n",
        "‚ö†Ô∏è  CUIDADOS:\n",
        "   * Puede sobreajustarse f√°cilmente\n",
        "   * Sensible a outliers\n",
        "   * M√°s lento que Random Forest\n",
        "\n",
        "‚úÖ CU√ÅNDO USARLO:\n",
        "   * Cuando necesitas m√°xima precisi√≥n\n",
        "   * Tienes tiempo para tunear par√°metros\n",
        "   * Los datos est√°n limpios\n",
        "\n",
        "‚ùå CU√ÅNDO NO USARLO:\n",
        "   * Datos muy ruidosos\n",
        "   * Necesitas resultados r√°pidos\n",
        "   * Dataset muy peque√±o"
      ],
      "metadata": {
        "id": "dJkwzY4YcwT2"
      }
    }
  ]
}